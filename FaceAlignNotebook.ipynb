{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aligning faces to create balanced face stimuli\n",
    "### this is a notebook implementation of the script align_faces.py (largely because of silly argparse issue - see below)\n",
    "\n",
    "#### This notebook takes input images, sets the eyes 45% of the height up the image (hard coded in facealigner - see path using inspect.getfile(FaceAligner) and makes the intereye distance 30% of the image (default) and writes out a 360, 256, 3 (H, W, RGB) image\n",
    "\n",
    "## No background removal yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/varunwadia/opt/anaconda3/lib/python3.8/site-packages/imutils/face_utils/facealigner.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "inspect.getfile(FaceAligner)\n",
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 4,
   "id": "e5a1ed9c-660c-4e9c-9e9a-a9b70b20706f",
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\u001b[0;32m      7\u001b[0m sam_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msam_vit_h_4b8939.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      8\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\wadiav\\documents\\python\\familiarity\\segment-anything\\segment_anything\\__init__.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the license found in the\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild_sam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     build_sam,\n\u001b[0;32m      9\u001b[0m     build_sam_vit_h,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     sam_model_registry,\n\u001b[0;32m     13\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpredictor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SamPredictor\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomatic_mask_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SamAutomaticMaskGenerator\n",
      "File \u001b[1;32mc:\\users\\wadiav\\documents\\python\\familiarity\\segment-anything\\segment_anything\\predictor.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sam\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResizeLongestSide\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamPredictor\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     20\u001b[0m         sam_model: Sam,\n\u001b[0;32m     21\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\users\\wadiav\\documents\\python\\familiarity\\segment-anything\\segment_anything\\utils\\transforms.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resize, to_pil_image  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cpu\" # GPU doesn't have enough compute and keep running out of memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akon.jpg\n",
      "cardi.jpg\n",
      "CB.jpg\n",
      "CM.jpg\n",
      "cube.jpg\n",
      "Drake.jpg\n",
      "EoN.jpg\n",
      "ES.jpg\n",
      "IA.jpg\n",
      "JH.jpg\n",
      "JTF.jpg\n",
      "JuBo.jpg\n",
      "Kdot.jpg\n",
      "KW.jpg\n",
      "MM.jpg\n",
      "MS.jpg\n",
      "MTG.jpg\n",
      "MV.jpg\n",
      "PD.jpg\n",
      "Ri.jpg\n",
      "SKB.jpg\n",
      "SKW.jpg\n",
      "Snoop.jpg\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rect \u001b[38;5;129;01min\u001b[39;00m rects:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# extract the ROI of the *original* face, then align the face\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# using facial landmarks\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     (x, y, w, h) \u001b[38;5;241m=\u001b[39m rect_to_bb(rect)\n\u001b[1;32m---> 87\u001b[0m     faceOrig \u001b[38;5;241m=\u001b[39m \u001b[43mimutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     faceAligned \u001b[38;5;241m=\u001b[39m fa\u001b[38;5;241m.\u001b[39malign(image, gray, rect)\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;66;03m# display the output images\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\imutils\\convenience.py:87\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(image, width, height, inter)\u001b[0m\n\u001b[0;32m     81\u001b[0m     dim \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(w \u001b[38;5;241m*\u001b[39m r), height)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# otherwise, the height is None\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# calculate the ratio of the width and construct the\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# dimensions\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwidth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m     dim \u001b[38;5;241m=\u001b[39m (width, \u001b[38;5;28mint\u001b[39m(h \u001b[38;5;241m*\u001b[39m r))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# resize the image\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "# sys.argv = ['']\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-p\", \"--shape-predictor\", required=True,\n",
    "help=\"path to facial landmark predictor\")\n",
    "ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "help=\"path to input image\")\n",
    "ap.add_argument(\"-o\", \"--output-file\", required=True,\n",
    "help=\"path to written image\")\n",
    "\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\SingleIm')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\SingleIm_Aligned')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\FamFaces_Pt_P87CS_2')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\FamFaces_Pt_P87CS_2_Aligned')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\FamFaces_Pt_P86CS')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\FamFaces_Pt_P86CS_Aligned')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P92CS\\FamFaces_Pt_P92CS')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P92CS\\FamFaces_Pt_P92CS_Aligned')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P92CS\\Im')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P92CS\\Im_Aligned')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P98CS\\ExtraFaces_Raw')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P98CS\\ExtraFaces_Aligned')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P98CS\\Im')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P98CS\\ExtraFaces_Aligned')\n",
    "\n",
    "imPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P99CS\\ExtraFaces_Raw')\n",
    "imageOutPath = os.path.join(os.getcwd(), 'BackgroundRemoval_SegAny\\P99CS\\ExtraFaces_Aligned')\n",
    "if os.path.exists(imageOutPath) is False:\n",
    "    os.mkdir(imageOutPath)\n",
    "    \n",
    "for files in os.listdir(imPath):\n",
    "    print(files)\n",
    "    im_path_in = os.path.join(imPath, files)\n",
    "    # print(im_path_in)\n",
    "    name = files.split('.')\n",
    "    # im_name_out = name[0] + '_H360' + '.' + name[1]\n",
    "    im_name_out = name[0] + '.' + name[1]\n",
    "    im_path_out = os.path.join(imageOutPath, im_name_out) \n",
    "    \n",
    "    argString = '--shape-predictor shape_predictor_68_face_landmarks.dat --image ' + im_path_in + ' '\\\n",
    "    + '--output-file ' + im_path_out \n",
    "    # print(argString)\n",
    "    args = vars(ap.parse_args(argString.split()))\n",
    "    \n",
    "    # initialize dlib's face detector (HOG-based) and then create\n",
    "    # the facial landmark predictor and the face aligner\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(args[\"shape_predictor\"])\n",
    "    fa = FaceAligner(predictor, desiredFaceWidth=256, desiredFaceHeight=360)\n",
    "    \n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "    image = cv2.imread(args[\"image\"])\n",
    "    image = imutils.resize(image, width=800) # is this too large?\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # show the original input image and detect faces in the grayscale\n",
    "    # image\n",
    "    # cv2.imshow(\"Input\", image)\n",
    "    rects = detector(gray, 2)\n",
    "\n",
    "    # loop over the face detections\n",
    "    for rect in rects:\n",
    "        # extract the ROI of the *original* face, then align the face\n",
    "        # using facial landmarks\n",
    "        (x, y, w, h) = rect_to_bb(rect)\n",
    "        faceOrig = imutils.resize(image[y:y + h, x:x + w], width=256)\n",
    "        faceAligned = fa.align(image, gray, rect)\n",
    "\n",
    "        # display the output images\n",
    "        cv2.imwrite(os.path.join(imageOutPath, im_name_out), faceAligned)\n",
    "        # cv2.imshow(\"Original\", faceOrig)\n",
    "        # cv2.imshow(\"Aligned\", faceAligned)\n",
    "        # cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rectangles[[(213, 250) (545, 583)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation of script call in loop. Technically cleaner but doesn't work yet because I haven't figured out how to pass \n",
    "#### arguments to argparses by reference and not by value \n",
    "#### eg. im_path_name = '100.jpg' if I use align_faces.py --image im_path_name the arg it will read is 'im_path_name' not the\n",
    "#### value inside im_path_name"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "imPath = os.path.join(os.getcwd(), 'images')\n",
    "imageOutPath = os.getcwd() + r'\\aligned'\n",
    "if os.path.exists(imageOutPath) is False:\n",
    "    os.mkdir(imageOutPath)\n",
    "    \n",
    "for files in os.listdir(imPath):\n",
    "    # print(files)\n",
    "    im_path_in = os.path.join(imPath, files)\n",
    "    # print(im_path_in)\n",
    "    name = files.split('.')\n",
    "    im_name_out = name[0] + '_H360' + '.' + name[1]\n",
    "    im_path_out = os.path.join(imageOutPath, im_name_out) \n",
    "    \n",
    "    %run align_faces.py \\\n",
    "    --shape-predictor shape_predictor_68_face_landmarks.dat \\\n",
    "    --image im_path_in \\\n",
    "    --output-path im_path_out[0]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
