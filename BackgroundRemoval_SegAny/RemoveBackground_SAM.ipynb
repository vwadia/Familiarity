{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook uses code from notebooks/automatic_mask_generator_example\n",
    "#### To load in images, run the default SAM model to create masks\n",
    "#### and use those masks to change the background of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Set-up - Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If running locally using jupyter, first install `segment_anything` in your environment using the [installation instructions](https://github.com/facebookresearch/segment-anything#installation) in the repository. If running from Google Colab, set `using_colab=True` below and run the cell. In Colab, be sure to select 'GPU' under 'Edit'->'Notebook Settings'->'Hardware accelerator'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_colab:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(\"PyTorch version:\", torch.__version__)\n",
    "    print(\"Torchvision version:\", torchvision.__version__)\n",
    "    print(\"CUDA is available:\", torch.cuda.is_available())\n",
    "    import sys\n",
    "    # !{sys.executable} -m pip install opencv-python matplotlib\n",
    "    # !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n",
    "    \n",
    "    # !mkdir images\n",
    "    # !wget -P images https://raw.githubusercontent.com/facebookresearch/segment-anything/main/notebooks/images/dog.jpg\n",
    "        \n",
    "    # !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up - Local"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 1,
   "id": "560725a2",
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\" # this is so that inline plotting doesn't crash the kernel"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 2,
   "id": "12032b22-1ea5-473c-b9e7-7d1384c71ee5",
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "'/Users/varunwadia/Documents/Familiarity/BackgroundRemoval_SegAny'"
      ]
     },
     "execution_count": 4,
=======
       "'C:\\\\Users\\\\wadiav\\\\Documents\\\\PYTHON\\\\Familiarity\\\\BackgroundRemoval_SegAny'"
      ]
     },
     "execution_count": 2,
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
<<<<<<< HEAD
=======
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98a0e0-1f53-4fdb-8088-8cd7150ed1e9",
   "metadata": {},
   "outputs": [],
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
   "source": [
    "os.chdir('C:\\\\Users\\\\wadiav\\\\Documents\\\\PYTHON\\\\Familiarity')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "  \n",
    "# Storing ID of current CUDA device\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(f\"ID of current CUDA device: {torch.cuda.current_device()}\")\n",
    "        \n",
    "print(f\"Name of current CUDA device: {torch.cuda.get_device_name(cuda_id)}\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 3,
   "id": "74b6e5f0",
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "# this crashes the kernel\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic mask generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run automatic mask generation, provide a SAM model to the `SamAutomaticMaskGenerator` class. Set the path below to the SAM checkpoint. Running on CUDA and with the default model is recommended."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9394149780273438\n"
=======
   "execution_count": 4,
   "id": "1848a108",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segment_anything'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m      3\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegment_anything\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n\u001b[0;32m      6\u001b[0m sam_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msam_vit_h_4b8939.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvit_h\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'segment_anything'"
>>>>>>> 1805866207574fa8d53eb63b720de7d806618e01
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "\n",
    "device = \"cpu\" # GPU doesn't have enough compute and keep running out of memory\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "# specific params for faces\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    sam, \n",
    "    points_per_batch=1024, \n",
    "    points_per_side=2,\n",
    "    min_mask_region_area=10000\n",
    ")\n",
    "# mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "t2 = time.time()\n",
    "\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_generator.point_grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imPath = os.path.join(os.getcwd(), 'P92CS\\FamFaces_Pt_P92CS_Aligned')\n",
    "imPath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in all images and run `generate` on them in turn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: This takes a long time - do this night before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imPath = os.path.join(os.getcwd(), 'CelebFaces_Pt_Varun_Aligned_100')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'CelebFaces_Pt_Varun_Processed_100')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'FewIms_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'FewIms_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P87CS_2_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P87CS_2_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P86CS_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P86CS_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'P92CS\\FamFaces_Pt_P92CS_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'P92CS\\FamFaces_Pt_P92CS_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'P98CS\\Im_Aligned')\n",
    "# # imPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Processed')\n",
    "\n",
    "imPath = os.path.join(os.getcwd(), 'P99CS\\ExtraFaces_Aligned')\n",
    "imageOutPath = os.path.join(os.getcwd(), 'P99CS\\ExtraFaces_Processed')\n",
    "\n",
    "# CHANGE THE OUTNAME OF MASKS AT THE BOTTOM OF LOOP TO MATCH FOLDER NAMES\n",
    "if os.path.exists(imageOutPath) is False:\n",
    "    os.mkdir(imageOutPath)\n",
    "    \n",
    "t1 = time.time()\n",
    "im_mask = list() \n",
    "ctr = 0 # lol python\n",
    "\n",
    "for files in os.listdir(imPath):\n",
    "    \n",
    "    # read in file\n",
    "    im_path_in = os.path.join(imPath, files)\n",
    "    image = cv2.imread(im_path_in)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # rename file\n",
    "    name = files.split('.')\n",
    "    prefix = name[0]\n",
    "    im_name_out = prefix.zfill(4) + '.' + name[1]\n",
    "    im_path_out = os.path.join(imageOutPath, im_name_out) \n",
    "    # print(im_path_out)\n",
    "    \n",
    "    # create masks and save\n",
    "    masks = mask_generator.generate(image) # create all masks\n",
    "    segsum = []\n",
    "    for i in range(len(masks)):\n",
    "        segsum.append(sum(sum(masks[i]['segmentation'])))\n",
    "    \n",
    "    chosenMask = max(enumerate(segsum),key=lambda x: x[1])[0]\n",
    "    newseg = masks[chosenMask]['segmentation'] # choose the last one\n",
    "    im_mask.append(newseg.astype(np.uint8)) # change variable time \n",
    "    ctr = ctr + 1\n",
    "    print(\"Finished for image \" + str(ctr))\n",
    "\n",
    "\n",
    "# outName = 'Mamelak_FamMask_P98CS_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "# outName = 'TJMiller_FamMask_P98CS_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "# outName = 'FamMasks_P98CS_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "outName = 'FamMasks_P99CS_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "# outName = 'FamMasks_P92CS_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "# outName = 'FewMasks_P86CS_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "np.save(outName,  im_mask)\n",
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(im_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outName"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the masks to create background subtracted pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imPath = os.path.join(os.getcwd(), 'CelebFaces_Pt_Varun_Aligned_100')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'CelebFaces_Pt_Varun_Processed_100')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P87CS_2_Aligned')\n",
    "# imPath = os.path.join(os.getcwd(), 'FewIms_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P87CS_2_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P86CS_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'FamFaces_Pt_P86CS_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'P92CS\\FamFaces_Pt_P92CS_Aligned')\n",
    "# imageOutPath = os.path.join(os.getcwd(), 'P92CS\\FamFaces_Pt_P92CS_Processed')\n",
    "\n",
    "# imPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Aligned')\n",
    "imPath = os.path.join(os.getcwd(), 'P98CS\\Im_Aligned')\n",
    "imageOutPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Processed')\n",
    "\n",
    "if os.path.exists(imageOutPath) is False:\n",
    "    os.mkdir(imageOutPath)\n",
    "\n",
    "# outName = 'FamMasks_' + str(len(os.listdir(imPath))) + '.npy'\n",
    "# outName = 'FamMasks_P87CS_2_' + str(len(os.listdir(imPath))) + '.npy'  \n",
    "\n",
    "im_mask = np.load(outName)\n",
    "colors = [192, 192, 192]\n",
    "ctr = 0\n",
    "\n",
    "for files in os.listdir(imPath):\n",
    "    # read in the image\n",
    "    im_path_in = os.path.join(imPath, files)\n",
    "    image = cv2.imread(im_path_in)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # name output file\n",
    "    name = files.split('.')\n",
    "    prefix = name[0]\n",
    "    im_name_out = prefix.zfill(4) + '.' + name[1]\n",
    "    im_path_out = os.path.join(imageOutPath, im_name_out) \n",
    "    \n",
    "    # read in the mask\n",
    "    mask_tile = im_mask[ctr].astype(np.uint8)\n",
    "    mask_tile = cv2.cvtColor(mask_tile,cv2.COLOR_GRAY2RGB)\n",
    "    mask_tile = mask_tile*255 # this is a stupid hack but sort of works\n",
    "\n",
    "    out = cv2.subtract(mask_tile, image)\n",
    "    out[np.where((out == [0, 0, 0]).all(axis = 2))] = [colors]\n",
    "    out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "    result = np.where(mask_tile, image, out)\n",
    "    \n",
    "    # print the result\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB) # else they print in BGR\n",
    "    cv2.imwrite(im_path_out, result)\n",
    "    print(\"Finished for image \" + str(ctr))\n",
    "    ctr = ctr + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for files in os.listdir(imPath):\n",
    "    name = files.split('.')\n",
    "    prefix = name[0]\n",
    "    if prefix in ['3505', '3029', '3033']:\n",
    "        print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageOutPath"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(len(masks))\n",
    "print(masks[0].keys())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "masks[0]['segmentation'].shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "np.shape(newseg)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Looking at the various masks"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this crashes the kernel for some annoying reason\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imPath = os.path.join(os.getcwd(), 'P92CS\\Im_Aligned')\n",
    "imPath = os.path.join(os.getcwd(), 'P98CS\\ExtraFaces_Aligned')\n",
    "\n",
    "# im_path_in = os.path.join(imPath, '3407.jpg')\n",
    "im_path_in = os.path.join(imPath, 'MileyC.jpg')\n",
    "image = cv2.imread(im_path_in)\n",
    "# image = cv2.imread('FamFaces_Pt_P87CS_2_Aligned/3009.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific params for faces\n",
    "mask_generator = SamAutomaticMaskGenerator(\n",
    "    sam, \n",
    "    points_per_batch=1024, \n",
    "    points_per_side=4,\n",
    "    min_mask_region_area=10000\n",
    ")\n",
    "masks = mask_generator.generate(image) # create all masks\n",
    "len(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newseg = list()\n",
    "for i in range(len(masks)):\n",
    "    # if np.array_equal(masks[i]['segmentation'], masks[i+1]['segmentation']) is False:\n",
    "        newseg.append(masks[i]['segmentation'].astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segsum = []\n",
    "for i in range(len(masks)):\n",
    "    segsum.append(sum(sum(masks[i]['segmentation'])))\n",
    "    \n",
    "chosenMask = max(enumerate(segsum),key=lambda x: x[1])[0]\n",
    "chosenMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newseg = masks[4]['segmentation'] +masks[0]['segmentation'] # choose the last one\n",
    "# newseg = masks[3]['segmentation'] # choose the last one\n",
    "newseg = masks[chosenMask]['segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(im_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in doggie case masks[0]['segmentation'] is what we want\n",
    "# For faces maybe use newseg[-1]? \n",
    "# immask = newseg[0].astype(np.uint8) + newseg[1].astype(np.uint8)\n",
    "immask = newseg.astype(np.uint8)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(immask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colors = [192, 192, 192]\n",
    "ori_img = image\n",
    "# mask_tile = np.tile(im_mask[:, :, np.newaxis], [1, 1, 3])\n",
    "mask_tile = cv2.cvtColor(immask,cv2.COLOR_GRAY2RGB)\n",
    "mask_tile = mask_tile*255 # this is a stupid hack but sort of works\n",
    "\n",
    "obtain_img = cv2.subtract(mask_tile, ori_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = obtain_img\n",
    "out[np.where((out == [0, 0, 0]).all(axis = 2))] = [colors]\n",
    "out = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "result = np.where(mask_tile, ori_img, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now print indiv fig if desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path_out = os.path.join(imageOutPath, 'MileyC.jpg') \n",
    "im_path_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "cv2.imwrite(im_path_out, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the mask to change the background and output the new image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic mask generation options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several tunable parameters in automatic mask generation that control how densely points are sampled and what the thresholds are for removing low quality or duplicate masks. Additionally, generation can be automatically run on crops of the image to get improved performance on smaller objects, and post-processing can remove stray pixels and holes. Here is an example configuration that samples more masks:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mask_generator_2 = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.5,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=4,\n",
    "    min_mask_region_area=200,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mask_generator_2 = SamAutomaticMaskGenerator(\n",
    "    model=sam,\n",
    "    points_per_side=2,\n",
    "    pred_iou_thresh=0.86,\n",
    "    stability_score_thresh=0.99,\n",
    "    crop_n_layers=1,\n",
    "    crop_n_points_downscale_factor=2,\n",
    "    min_mask_region_area=200,  # Requires open-cv to run post-processing\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "t1 = time.time()\n",
    "masks2 = mask_generator_2.generate(image) # this takes several minutes - don't need this\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(masks2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)\n",
    "show_anns(masks2)\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
